{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# MCP Toolbox on Vertex AI Agent Engine with custom installation scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Vertex AI Agent Engine provides **support for custom installation and startup scripts**. This means you can now run shell scripts you need during your agent's build and startup process. You can install custom binaries, compile code from source, or set up any other specialized dependency your agent requires.\n",
        "\n",
        "Most importantly, this feature means unlocks a new pattern for deploying agents with complex, standardized tools. In fact, you can now **deploy agents using the Model Context Protocol (MCP) on Vertex AI Agent Engine**.\n",
        "\n",
        "This guide shows you how to build, test, and deploy a custom Reddit agent that uses an MCP server, demonstrating this new pattern for creating custom agents on Vertex AI Agent Engine.\n",
        "\n",
        "**What You'll Learn**\n",
        "\n",
        "  * How to set up your local environment for agent development.\n",
        "  * How to run MCP Toolbox locally with Python, BigQuery, and ADK.\n",
        "  * How to build and test an agent locally using the Google Agent Development Kit (ADK).\n",
        "  * How to use the \"bring your own installation and startup script\" feature to deploy the agent w/ MCP toolbox to Vertex AI Agent Engine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK and other required packages\n",
        "\n",
        "Run the following command to install the Vertex AI SDK with the necessary extras for Agent Engine and the ADK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa0524a-9d7a-455a-cad8-2ef8a45cc5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'cryptography==3.4.8--upgrade': Expected end or semicolon (after version specifier)\n",
            "    cryptography==3.4.8--upgrade\n",
            "                ~~~~~~~^\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install \"google-cloud-aiplatform[agent_engines,adk]\" \"aiofiles\" \"cryptography==3.4.8\"--upgrade --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuDxcQBeWHwh"
      },
      "source": [
        "**Important:** After the installation completes, you must restart your Colab or notebook kernel for the new packages to be recognized.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Next, authenticate your account and initialize the Vertex AI SDK. This allows your environment to interact with your Google Cloud project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e438f4-b3ec-4e19-f8e9-a325fc532096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: google.colab.auth.authenticate_user() is not supported in Colab Enterprise.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"global\")\n",
        "\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "BUCKET_NAME = \"\"  # @param {type: \"string\", placeholder: \"[your-bucket-name]\", isTemplate: true}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "\n",
        "#! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}\n",
        "\n",
        "# Set environment variables required for ADK\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"TRUE\"\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
      ],
      "metadata": {
        "id": "sTPA8pdHSSbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaTpAWU_urge"
      },
      "source": [
        "## Import required libraries\n",
        "\n",
        "Import the necessary libraries from the ADK, Vertex AI SDK, and Python's standard library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mwd3-fcsuvHl"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.getLogger(\"google_adk\").setLevel(logging.CRITICAL)\n",
        "logging.getLogger(\"asyncio\").setLevel(logging.CRITICAL)\n",
        "import os\n",
        "import uuid\n",
        "from typing import Any, Iterator, Optional\n",
        "\n",
        "import aiofiles\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.artifacts import InMemoryArtifactService\n",
        "from google.adk.memory import InMemoryMemoryService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools.mcp_tool import StdioConnectionParams\n",
        "from google.adk.tools.mcp_tool.mcp_toolset import (MCPToolset,\n",
        "                                                   StdioServerParameters)\n",
        "from google.genai import types\n",
        "from vertexai import agent_engines\n",
        "from vertexai.agent_engines import AgentEngine\n",
        "from vertexai.preview.reasoning_engines import AdkApp\n",
        "from toolbox_core import ToolboxSyncClient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5fnMisOCxBZ"
      },
      "source": [
        "### Helper function\n",
        "\n",
        "This tutorial uses a helper function, `chat_loop`, to provide a consistent interactive chat interface for testing the agent in both local and deployed environments. This function abstracts the differences between interacting with a local ADK Runner and a remote AgentEngine instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Sgp2_wsP9tlw"
      },
      "outputs": [],
      "source": [
        "def chat_loop(\n",
        "    app, user_id: Optional[str] = None, session_id: Optional[str] = None\n",
        ") -> None:\n",
        "    \"\"\"Interactive chat loop for AI applications.\"\"\"\n",
        "\n",
        "    # Simple setup\n",
        "    user_id = user_id or f\"u_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "    # Handle session based on app type\n",
        "    if isinstance(app, (AdkApp, AgentEngine)):\n",
        "        # Only create session if session_id is not provided\n",
        "        if not session_id:\n",
        "            session = app.create_session(user_id=user_id)\n",
        "            # Handle both dict and object session responses\n",
        "            if isinstance(session, dict):\n",
        "                session_id = session[\"id\"]\n",
        "            else:\n",
        "                session_id = session.id\n",
        "\n",
        "        def query_fn(msg: str):\n",
        "            return app.stream_query(user_id=user_id, session_id=session_id, message=msg)\n",
        "\n",
        "    elif isinstance(app, Runner):\n",
        "        session_id = session_id or f\"s_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "        def query_fn(msg: str):\n",
        "            return app.run(\n",
        "                user_id=user_id,\n",
        "                session_id=session_id,\n",
        "                new_message=types.Content(role=\"user\", parts=[types.Part(text=msg)]),\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        raise TypeError(\n",
        "            f\"Unsupported app type: {type(app)}. Expected AdkApp, AgentEngine, or Runner.\"\n",
        "        )\n",
        "\n",
        "    _print_startup_info(user_id, session_id)\n",
        "\n",
        "    # Main loop\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nYou: \").strip()\n",
        "            if not user_input or user_input.lower() in {\"quit\", \"exit\", \"bye\"}:\n",
        "                break\n",
        "\n",
        "            print(\"\\nAssistant: \", end=\"\", flush=True)\n",
        "\n",
        "            response = _get_response_text(query_fn(user_input))\n",
        "            print(response or \"(No response generated)\")\n",
        "\n",
        "        except (KeyboardInterrupt, EOFError):\n",
        "            print(\"\\n\\nüõë Chat interrupted.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(\"\\nüëã Goodbye!\")\n",
        "\n",
        "\n",
        "def _print_startup_info(user_id: str, session_id: str) -> None:\n",
        "    \"\"\"Print startup information.\"\"\"\n",
        "    print(\"\\nüöÄ Starting chat...\")\n",
        "    print(f\"üë§ User ID: {user_id}\")\n",
        "    print(f\"üìÅ Session ID: {session_id}\")\n",
        "    print(\"üí¨ Type 'exit' or 'quit' to end.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "def _get_response_text(events: Iterator[Any]) -> str:\n",
        "    \"\"\"Extract response text from event stream.\"\"\"\n",
        "    responses = []\n",
        "\n",
        "    for event in events:\n",
        "        # Handle dict-like events (AgentEngine format)\n",
        "        if isinstance(event, dict):\n",
        "            text = _extract_from_dict_event(event)\n",
        "        # Handle object-like events\n",
        "        else:\n",
        "            text = _extract_from_object_event(event)\n",
        "\n",
        "        if text:\n",
        "            responses.append(text)\n",
        "            # Print streaming text in real-time\n",
        "            print(text, end=\"\", flush=True)\n",
        "\n",
        "    return \"\".join(responses)\n",
        "\n",
        "\n",
        "def _extract_from_dict_event(event: dict) -> Optional[str]:\n",
        "    \"\"\"Extract text from dictionary-style events (AgentEngine format).\"\"\"\n",
        "    # Handle AgentEngine response format\n",
        "    if \"parts\" in event and \"role\" in event:\n",
        "        # Only extract text from model responses, skip function calls/responses\n",
        "        if event.get(\"role\") == \"model\":\n",
        "            parts = event.get(\"parts\", [])\n",
        "            text_parts = []\n",
        "\n",
        "            for part in parts:\n",
        "                # Extract text content, skip function calls\n",
        "                if isinstance(part, dict) and \"text\" in part:\n",
        "                    text_parts.append(part[\"text\"])\n",
        "\n",
        "            return \"\".join(text_parts) if text_parts else None\n",
        "        return None\n",
        "\n",
        "    # Handle other dict formats\n",
        "    content = event.get(\"content\", {})\n",
        "    if isinstance(content, str):\n",
        "        return content\n",
        "\n",
        "    parts = content.get(\"parts\", [])\n",
        "    if not parts:\n",
        "        return None\n",
        "\n",
        "    text_parts = []\n",
        "    for part in parts:\n",
        "        if isinstance(part, dict) and \"text\" in part:\n",
        "            text_parts.append(part[\"text\"])\n",
        "\n",
        "    return \"\".join(text_parts) if text_parts else None\n",
        "\n",
        "\n",
        "def _extract_from_object_event(event: Any) -> Optional[str]:\n",
        "    \"\"\"Extract text from object-style events.\"\"\"\n",
        "    # Handle string content directly\n",
        "    content = getattr(event, \"content\", None)\n",
        "    if isinstance(content, str):\n",
        "        return content\n",
        "\n",
        "    # Handle content with parts\n",
        "    if content and hasattr(content, \"parts\"):\n",
        "        text_parts = []\n",
        "        for part in content.parts:\n",
        "            if hasattr(part, \"text\") and part.text:\n",
        "                text_parts.append(part.text)\n",
        "        return \"\".join(text_parts) if text_parts else None\n",
        "\n",
        "    # Handle direct text attribute\n",
        "    return getattr(event, \"text\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCh91WIcXITc"
      },
      "source": [
        "## Building the Agent Locally\n",
        "\n",
        "Before deployment, the agent is built and tested in the local environment. This allows for rapid iteration and debugging.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XIzMtR_rcUN"
      },
      "source": [
        "### Prepare the installation script\n",
        "\n",
        "The agent uses an external tool, `mcp-reddit`, which must be installed in the runtime environment. A shell script will be created to handle this installation. Vertex AI Agent Engine will execute this script during the deployment process.\n",
        "\n",
        "First, create a local directory to store the script.\n",
        "\n",
        "Then, the script performs the following actions:\n",
        "- Updates the package index and installs curl.\n",
        "- Installs uv, a fast Python package manager, to accelerate dependency installation.\n",
        "- Adds uv to the system's PATH.\n",
        "- Uses uv to install the mcp-reddit package directly from its Git repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-9KwhvQtr0-f"
      },
      "outputs": [],
      "source": [
        "!mkdir -p installation_scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q5f_iAu-k9e5"
      },
      "outputs": [],
      "source": [
        "install_local_mcp_file = \"\"\"\n",
        "#!/bin/bash\n",
        "# Exit immediately if a command exits with a non-zero status.\n",
        "set -e\n",
        "\n",
        "echo \"Installing MCP Toolbox Server\"\n",
        "\n",
        "# Install uv (a fast Python package manager)\n",
        "apt-get update\n",
        "apt-get install -y curl\n",
        "\n",
        "echo \"Installing MCP Toolbox\"\n",
        "\n",
        "export OS=\"linux/amd64\" # one of linux/amd64, darwin/arm64, darwin/amd64, or windows/amd64\n",
        "curl -O https://storage.googleapis.com/genai-toolbox/v0.12.0/$OS/toolbox\n",
        "\n",
        "pwd\n",
        "ls -ltr\n",
        "\n",
        "chmod 755 toolbox\n",
        "\n",
        "# Install the MCP Toolbox using the command from its documentation\n",
        "\n",
        "echo \"Installing uv\"\n",
        "\n",
        "curl -LsSf https://astral.sh/uv/install.sh | env UV_INSTALL_DIR=\"/usr/local/bin\" sh\n",
        "\n",
        "# Add uv to PATH for current session\n",
        "export PATH=\"$HOME/.local/bin:$PATH\"\n",
        "\n",
        "# Install the MCP Toolbox using the command from its documentation\n",
        "echo \"Installing MCP Toolbox using uv...\"\n",
        "uv pip install toolbox-core --system\n",
        "echo \"MCP Toolbox Server installation complete.\"\n",
        "\"\"\"\n",
        "\n",
        "with open(\"installation_scripts/install_local_mcp.sh\", \"w\") as f:\n",
        "    f.write(install_local_mcp_file)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p startup_scripts"
      ],
      "metadata": {
        "id": "o-kD93xdSd_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_uv_file = \"\"\"\n",
        "#!/bin/bash\n",
        "# Exit immediately if a command exits with a non-zero status.\n",
        "set -e\n",
        "\n",
        "echo \"Starting MCP Toolbox Server\"\n",
        "\n",
        "./toolbox --tools-file \"tools.yaml\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"startup_scripts/init_uv.sh\", \"w\") as f:\n",
        "    f.write(init_uv_file)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "6a6Oz8BcxYxy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYmyvnTO2j9f"
      },
      "outputs": [],
      "source": [
        "!chmod +x installation_scripts/install_local_mcp.sh && ./installation_scripts/install_local_mcp.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgTU1HTasbvO"
      },
      "source": [
        "### Defining the Agent\n",
        "\n",
        "Here, we define the `LlmAgent` using ADK. We provide a detailed prompt and connect it to our `MCPToolset`, pointing it to the runner script. We define our agent's using a factory function. The main test loop will then call this function to create an agent instance, providing it with the necessary async log file handle at runtime.\n",
        "\n",
        "> **Notice**: To solve the `fileno` error in Colab, we must redirect the tool's error stream to a file that supports asynchronous operations. We will use the aiofiles library for this. This requires our test to run inside an async function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1Lha44dp9CCk"
      },
      "outputs": [],
      "source": [
        "def create_agent(errlog):\n",
        "    root_agent = LlmAgent(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        name=\"reddit_assistant_agent\",\n",
        "        instruction=\"Help the user fetch reddit info.\",\n",
        "        tools=[\n",
        "            MCPToolset(\n",
        "                connection_params=StdioConnectionParams(\n",
        "                    server_params=StdioServerParameters(\n",
        "                        command=\"mcp-reddit\",\n",
        "                    ),\n",
        "                ),\n",
        "                errlog=errlog,  # Required only in colab environment\n",
        "            )\n",
        "        ],\n",
        "    )\n",
        "    return root_agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agent(errlog):\n",
        "\n",
        "    toolbox_client = ToolboxSyncClient(\"http://127.0.0.1:5000\")\n",
        "    agent_toolset = toolbox_client.load_toolset(\"my-toolset\")\n",
        "\n",
        "    # --- Define the Agent's Prompt ---\n",
        "    prompt = \"\"\"\n",
        "      You're a helpful hotel assistant. You handle hotel searching, booking and\n",
        "      cancellations. When the user searches for a hotel, mention it's name, id,\n",
        "      location and price tier. Always mention hotel ids while performing any\n",
        "      searches. This is very important for any operations. For any bookings or\n",
        "      cancellations, please provide the appropriate confirmation. Be sure to\n",
        "      update checkin or checkout dates if mentioned by the user.\n",
        "      Don't ask for confirmations from the user.\n",
        "    \"\"\"\n",
        "\n",
        "    root_agent = LlmAgent(\n",
        "        model='gemini-2.5-flash',\n",
        "        name='hotel_agent',\n",
        "        description='A helpful AI assistant that can search and book hotels.',\n",
        "        instruction=prompt,\n",
        "        tools=agent_toolset, # Pass the loaded toolset\n",
        "    )\n",
        "    return root_agent"
      ],
      "metadata": {
        "id": "nuM4IyTireI4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t6ceQ0IuVPg"
      },
      "source": [
        "### Test the agent locally\n",
        "\n",
        "Test the agent on the local machine to verify its functionality before deploying to the cloud.\n",
        "\n",
        "The local test setup involves:\n",
        "- Instantiating in-memory versions of the SessionService, MemoryService, and ArtifactService for lightweight local testing.\n",
        "- Creating an async file handle for the tool's error log.\n",
        "- Initializing the ADK Runner, which orchestrates the interaction between the user and the agent.\n",
        "- Calling the chat_loop helper to start an interactive conversation with the agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z6UiAGbT-jLp"
      },
      "outputs": [],
      "source": [
        "async def test_agent_locally():\n",
        "\n",
        "    # Create the session service\n",
        "    session_service = InMemorySessionService()\n",
        "    memory_service = InMemoryMemoryService()  # Add this line\n",
        "    artifact_service = InMemoryArtifactService() # Add this line\n",
        "\n",
        "    # Create the specific session where the conversation will happen\n",
        "    user_id = \"runner_user_01\"\n",
        "    session = await session_service.create_session(\n",
        "        app_name=\"MyRunnerApp\", user_id=user_id\n",
        "    )\n",
        "\n",
        "    # Initialize the Runner with the correct session service\n",
        "    errlog = await aiofiles.open(\n",
        "        \"error.log\", \"w+\"\n",
        "    )  # Required only in colab environment.\n",
        "    root_agent = create_agent(errlog)\n",
        "\n",
        "    runner = Runner(\n",
        "        agent=root_agent,\n",
        "        app_name=\"MyRunnerApp\",\n",
        "        session_service=session_service,\n",
        "        memory_service=memory_service,\n",
        "        artifact_service=artifact_service,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        chat_loop(runner, user_id, session.id)\n",
        "    finally:\n",
        "        # Ensure the log file is always closed\n",
        "        await errlog.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow Step 1 in https://googleapis.github.io/genai-toolbox/samples/bigquery/local_quickstart/ to set up your BigQuery Dataset and Table"
      ],
      "metadata": {
        "id": "YkiYXNFwSwyw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7d4c5b3b2f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c06496-ca20-4a10-f61c-6926e6c1ab51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting chat...\n",
            "üë§ User ID: runner_user_01\n",
            "üìÅ Session ID: bae6687b-a4a6-468d-909a-7d54ea6022c4\n",
            "üí¨ Type 'exit' or 'quit' to end.\n",
            "--------------------------------------------------\n",
            "\n",
            "You: hi\n",
            "\n",
            "Assistant: Hello! I'm a helpful hotel assistant. I can search, book, and cancel hotel reservations for you. How may I help you today?\n",
            "Hello! I'm a helpful hotel assistant. I can search, book, and cancel hotel reservations for you. How may I help you today?\n",
            "\n",
            "\n",
            "You: book a hotel in zurich\n",
            "\n",
            "Assistant: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the hotels I found in Zurich:\n",
            "\n",
            "*   **Courtyard Zurich** (ID: 9) - Location: Zurich, Price Tier: Upscale\n",
            "*   **Marriott Zurich** (ID: 2) - Location: Zurich, Price Tier: Upscale\n",
            "*   **Sheraton Zurich** (ID: 7) - Location: Zurich, Price Tier: Upper Upscale\n",
            "\n",
            "Which hotel would you like to book? Please provide the Hotel ID.Here are the hotels I found in Zurich:\n",
            "\n",
            "*   **Courtyard Zurich** (ID: 9) - Location: Zurich, Price Tier: Upscale\n",
            "*   **Marriott Zurich** (ID: 2) - Location: Zurich, Price Tier: Upscale\n",
            "*   **Sheraton Zurich** (ID: 7) - Location: Zurich, Price Tier: Upper Upscale\n",
            "\n",
            "Which hotel would you like to book? Please provide the Hotel ID.\n",
            "\n",
            "You: quit\n",
            "\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "await test_agent_locally()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShSFCOuFgb_I"
      },
      "source": [
        "## Deploying to Vertex AI Agent Engine\n",
        "\n",
        "With our agent tested and working locally, it's time to deploy our MCP-enabled agent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEpQB0kb_Cln"
      },
      "source": [
        "### Create the agent module\n",
        "\n",
        "Since ADK 1.0.0, the `MCPToolset` contains non-serializable (non-pickleable) state, such as thread locks.\n",
        "\n",
        "To deploy an agent with such a toolset, it must be wrapped in a `ModuleAgent`. This approach involves defining the agent in a separate Python file (`root_agent.py`) and referencing it by the module and variable name during deployment.\n",
        "\n",
        "\n",
        "This agent module file defines the full application, including service builders for `VertexAiSessionService`, which are the cloud-based counterparts to the in-memory services used for local testing. The agent itself is wrapped in an AdkApp object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UwF1E-twlNdr"
      },
      "outputs": [],
      "source": [
        "root_agent_file = f\"\"\"\n",
        "import os\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, StdioServerParameters\n",
        "from google.adk.tools.mcp_tool import StdioConnectionParams\n",
        "from vertexai.preview.reasoning_engines import AdkApp\n",
        "from toolbox_core import ToolboxSyncClient\n",
        "\n",
        "# Set variable\n",
        "PROJECT_ID=os.getenv('PROJECT_ID', '{PROJECT_ID}')\n",
        "LOCATION=os.getenv('LOCATION', '{LOCATION}')\n",
        "BUCKET_NAME=os.getenv('BUCKET_NAME', '{BUCKET_NAME}')\n",
        "\n",
        "# Define session builder\n",
        "def session_service_builder():\n",
        "  # This is needed to ensure InitGoogle and AdkApp setup is called first.\n",
        "  from google.adk.sessions import VertexAiSessionService\n",
        "  return VertexAiSessionService(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "toolbox_client = ToolboxSyncClient(\"http://127.0.0.1:5000\")\n",
        "agent_toolset = toolbox_client.load_toolset(\"my-toolset\")\n",
        "\n",
        "agent_app = AdkApp(\n",
        "    agent=LlmAgent(\n",
        "        model='gemini-2.5-flash',\n",
        "        name='hotel_agent',\n",
        "        description='A helpful AI assistant that can search and book hotels.',\n",
        "        instruction='You are a helpful hotel assistant. You handle hotel searching, booking and cancellations. When the user searches for a hotel, mention its name, id, location and price tier. Always mention hotel ids while performing any searches. This is very important for any operations. For any bookings or cancellations, please provide the appropriate confirmation. Be sure to update checkin or checkout dates if mentioned by the user. Do not ask for confirmations from the user.',\n",
        "        tools=agent_toolset, # Pass the loaded toolset\n",
        "    ),\n",
        "    session_service_builder=session_service_builder\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"root_agent.py\", \"w\") as f:\n",
        "    f.write(root_agent_file)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebj7YOeSskCW"
      },
      "source": [
        "### Deploy the agent\n",
        "\n",
        "The agent_engines.create() function is used to deploy the agent. The configuration specifies several key parameters:\n",
        "\n",
        "- `agent_engine`: An `agent_engines.ModuleAgent` is used, pointing to the `root_agent.py` file (module_name) and the `agent_app` variable within it (agent_name).\n",
        "\n",
        "- `requirements`: A list of standard Python package dependencies.\n",
        "\n",
        "- `extra_packages`: A list of local files to be included in the build. This must include the agent module file (`root_agent.py`) and the custom installation script.\n",
        "\n",
        "- `env_vars`: A dictionary of environment variables to be set in the deployed container, used here to securely pass the Reddit API credentials.\n",
        "\n",
        "- `build_options`: This dictionary specifies custom build-time operations. The installation key is used to provide a list of scripts that will be executed before the application server starts. This is where the custom installation script is specified.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8E6NRMJu_cGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3977a2-6088-408e-b64e-39c020321276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.agent_engines:Identified the following requirements: {'google-cloud-aiplatform': '1.122.0', 'cloudpickle': '3.1.1', 'pydantic': '2.12.3'}\n",
            "WARNING:vertexai.agent_engines:The following requirements are missing: {'cloudpickle', 'pydantic'}\n",
            "INFO:vertexai.agent_engines:The following requirements are appended: {'pydantic==2.12.3', 'cloudpickle==3.1.1'}\n",
            "INFO:vertexai.agent_engines:The final list of requirements: ['google-cloud-aiplatform[agent_engines,adk]>=1.101.0', 'toolbox-core', 'pydantic==2.12.3', 'cloudpickle==3.1.1']\n",
            "INFO:vertexai.agent_engines:Using bucket zyagent-staging\n",
            "INFO:vertexai.agent_engines:Wrote to gs://zyagent-staging/agent_engine/agent_engine.pkl\n",
            "INFO:vertexai.agent_engines:Writing to gs://zyagent-staging/agent_engine/requirements.txt\n",
            "INFO:vertexai.agent_engines:Creating in-memory tarfile of extra_packages\n",
            "INFO:vertexai.agent_engines:Writing to gs://zyagent-staging/agent_engine/dependencies.tar.gz\n",
            "/usr/local/lib/python3.11/dist-packages/vertexai/preview/reasoning_engines/templates/adk.py:587: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  self._tmpl_attrs[\"credential_service\"] = InMemoryCredentialService()\n",
            "/usr/local/lib/python3.11/dist-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  super().__init__()\n",
            "INFO:vertexai.agent_engines:Creating AgentEngine\n",
            "INFO:vertexai.agent_engines:Create AgentEngine backing LRO: projects/634751406259/locations/asia-southeast1/reasoningEngines/294035797546369024/operations/5029306373179965440\n",
            "INFO:vertexai.agent_engines:View progress and logs at https://console.cloud.google.com/logs/query?project=jeremychoock-sandbox\n",
            "INFO:vertexai.agent_engines:AgentEngine created. Resource name: projects/634751406259/locations/asia-southeast1/reasoningEngines/294035797546369024\n",
            "INFO:vertexai.agent_engines:To use this AgentEngine in another session:\n",
            "INFO:vertexai.agent_engines:agent_engine = vertexai.agent_engines.get('projects/634751406259/locations/asia-southeast1/reasoningEngines/294035797546369024')\n"
          ]
        }
      ],
      "source": [
        "remote_app = agent_engines.create(\n",
        "    display_name=\"bigquery_toolbox_agent\",\n",
        "    description=\"A bigquery toolbox agent with MCP\",\n",
        "    agent_engine=agent_engines.ModuleAgent(\n",
        "        module_name=\"root_agent\",\n",
        "        agent_name=\"agent_app\",\n",
        "        register_operations={\n",
        "            \"\": [\"get_session\", \"list_sessions\", \"create_session\", \"delete_session\"],\n",
        "            \"async\": [\n",
        "                \"async_get_session\",\n",
        "                \"async_list_sessions\",\n",
        "                \"async_create_session\",\n",
        "                \"async_delete_session\",\n",
        "            ],\n",
        "            \"stream\": [\"stream_query\", \"streaming_agent_run_with_events\"],\n",
        "            \"async_stream\": [\"async_stream_query\"],\n",
        "        },\n",
        "    ),\n",
        "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]>=1.101.0\",\"toolbox-core\"],\n",
        "    extra_packages=[\n",
        "        \"root_agent.py\",\n",
        "        \"startup_scripts/init_uv.sh\",\n",
        "        \"installation_scripts/install_local_mcp.sh\",\n",
        "        \"tools.yaml\",\n",
        "    ],\n",
        "    env_vars={\n",
        "        \"PROJECT_ID\": PROJECT_ID,\n",
        "        \"LOCATION\": LOCATION,\n",
        "    },\n",
        "    build_options={\n",
        "        \"installation\": [\n",
        "            \"installation_scripts/install_local_mcp.sh\",\n",
        "        ],\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWP0Vijjs_0T"
      },
      "source": [
        "After deployment, the chat_loop function can be used again to interact with the now remotely-hosted agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i7psp3vVBbG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7997c8f5-fb54-4cc2-d8a8-a6cb3ebb0056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting chat...\n",
            "üë§ User ID: u_c61e89e6\n",
            "üìÅ Session ID: 1273476907278532608\n",
            "üí¨ Type 'exit' or 'quit' to end.\n",
            "--------------------------------------------------\n",
            "\n",
            "Assistant: Hello! I'm a hotel assistant. I can help you with searching, booking, and canceling hotels. How may I help you today?\n",
            "Hello! I'm a hotel assistant. I can help you with searching, booking, and canceling hotels. How may I help you today?\n",
            "\n",
            "\n",
            "Assistant: Great! Do you have a specific hotel in mind, or are you looking for suggestions in a particular location? I'll need the hotel's name or ID to book it for you.Great! Do you have a specific hotel in mind, or are you looking for suggestions in a particular location? I'll need the hotel's name or ID to book it for you.\n",
            "\n",
            "Assistant: I couldn't find any hotels in Zuellig. Is there another location I can search for you?I couldn't find any hotels in Zuellig. Is there another location I can search for you?\n",
            "\n",
            "Assistant: Here are some hotels in Zurich:\n",
            "\n",
            "*   **Courtyard Zurich** (ID: 9) - Located in Zurich, Price Tier: Upscale\n",
            "*   **Marriott Zurich** (ID: 2) - Located in Zurich, Price Tier: Upscale\n",
            "*   **Sheraton Zurich** (ID: 7) - Located in Zurich, Price Tier: Upper Upscale\n",
            "\n",
            "Which one would you like to book, or would you like to search for another location?Here are some hotels in Zurich:\n",
            "\n",
            "*   **Courtyard Zurich** (ID: 9) - Located in Zurich, Price Tier: Upscale\n",
            "*   **Marriott Zurich** (ID: 2) - Located in Zurich, Price Tier: Upscale\n",
            "*   **Sheraton Zurich** (ID: 7) - Located in Zurich, Price Tier: Upper Upscale\n",
            "\n",
            "Which one would you like to book, or would you like to search for another location?\n",
            "\n",
            "You: quit\n",
            "\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "chat_loop(remote_app)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To avoid incurring ongoing charges to your Google Cloud account for the resources used in this tutorial, delete the resources you created. This section provides commands to delete the deployed Agent Engine and the associated Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a715oFmGKu4Y"
      },
      "outputs": [],
      "source": [
        "delete_agent_engine = True\n",
        "delete_bucket = True\n",
        "\n",
        "if delete_agent_engine:\n",
        "    agent_engines = agent_engines.list(filter=\"display_name=reddit_assistant_agent\")\n",
        "    for agent_engine in agent_engines:\n",
        "        agent_engine.delete(force=True)\n",
        "\n",
        "if delete_bucket:\n",
        "    !gsutil rm -r {BUCKET_URI}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "project_alchemy_mcp_on_agent_engine.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
